{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "98bd1946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.support.ui import WebDriverWait\n",
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# try:\n",
    "#     # waits up to 10 seconds for the element to be present, checks every 500 ms\n",
    "#     next_button = WebDriverWait(driver, 10).until(\n",
    "#         EC.presence_of_element_located((By.ID, \"ember234\"))\n",
    "#     )\n",
    "#     next_button.click()\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(str(e))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e162f3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # If finding by ID fails, try to find the element by aria-label\n",
    "# next_button = WebDriverWait(driver, 10).until(\n",
    "#     EC.presence_of_element_located((By.CSS_SELECTOR, \"button[aria-label='Next']\"))\n",
    "# )\n",
    "# next_button.click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f0b8d50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.support.ui import WebDriverWait\n",
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# def click_next_button(driver):\n",
    "\n",
    "#     try:\n",
    "#         # If finding by ID fails, try to find the element by aria-label\n",
    "#         next_button = WebDriverWait(driver, 10).until(\n",
    "#             EC.presence_of_element_located((By.CSS_SELECTOR, \"button[aria-label='Next']\"))\n",
    "#         )\n",
    "#         driver.execute_script(\"arguments[0].scrollIntoView();\", next_button)\n",
    "#         next_button.click()\n",
    "\n",
    "#     except Exception as e2:\n",
    "#         print(f\"Failed to find by aria-label, error: {str(e2)}\")\n",
    "# click_next_button(driver)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f0f086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9626663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cb6d65fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.support.ui import WebDriverWait\n",
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "\n",
    "# try:\n",
    "#     # Try to find the element by ID\n",
    "#     next_button = WebDriverWait(driver, 10).until(\n",
    "#         EC.presence_of_element_located((By.ID, \"ember234\"))\n",
    "#     )\n",
    "#     next_button.click()\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"Failed to find by ID, error: {str(e)}\")\n",
    "#     print(\"Trying to find by aria-label...\")\n",
    "\n",
    "#     try:\n",
    "#         # If finding by ID fails, try to find the element by aria-label\n",
    "#         next_button = WebDriverWait(driver, 10).until(\n",
    "#             EC.presence_of_element_located((By.CSS_SELECTOR, \"button[aria-label='Next']\"))\n",
    "#         )\n",
    "#         next_button.click()\n",
    "        \n",
    "#     except Exception as e2:\n",
    "#         print(f\"Failed to find by aria-label, error: {str(e2)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5066c5c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c7eebe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2643c75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d0799b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabf581a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81ebdd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57fbaef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()  # take environment variables from .env.\n",
    "os.environ[\"OPENAI_API_KEY\"]  = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "274d0308",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def find_linkedin_info(driver):\n",
    "#     time.sleep(5)  # Allow the page to load\n",
    "\n",
    "    # Get the source HTML of the page\n",
    "    source = driver.page_source\n",
    "\n",
    "    # Parse the source HTML with BeautifulSoup\n",
    "    soup = BeautifulSoup(source, 'lxml')\n",
    "\n",
    "    # Get the text from the parsed HTML\n",
    "    page_text = soup.get_text()\n",
    "    \n",
    "    # Split the text into lines and remove empty lines\n",
    "    lines = page_text.split('\\n')\n",
    "    non_empty_lines = [line for line in lines if line.strip() != \"\"]\n",
    "\n",
    "    # Join the non-empty lines back into a single string\n",
    "    url_text = \"\\n\".join(non_empty_lines)\n",
    "\n",
    "    return url_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3c7039c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "class Extractor:\n",
    "    '''\n",
    "    \n",
    "To request an appropriate pattern or string match for this class, you could ask:\n",
    "\n",
    "\"Please provide a string or a regular expression pattern that we should use for the start \n",
    "rule or end rule. If you provide a regular expression pattern, please specify that it is \n",
    "a regex. Also, note that for regular expressions, we're using Python's 're' module, so the \n",
    "pattern should be compatible with it. If you want to extract from the start or end of the \n",
    "text when no matching rule is found, please indicate that as well.\"\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.start_rules = []\n",
    "        self.end_rules = []\n",
    "\n",
    "    def add_start_rule(self, rule, is_regex=False):\n",
    "        self.start_rules.append((rule, is_regex))\n",
    "\n",
    "    def add_end_rule(self, rule, is_regex=False):\n",
    "        self.end_rules.append((rule, is_regex))\n",
    "\n",
    "    def extract(self, text, extract_if_no_start=False, extract_if_no_end=False):\n",
    "        if len(self.start_rules) > 0 and not extract_if_no_start:\n",
    "            start_index = None\n",
    "        else:\n",
    "            start_index = 0\n",
    "\n",
    "        if len(self.end_rules) > 0 and not extract_if_no_end:\n",
    "            end_index = None\n",
    "        else:\n",
    "            end_index = len(text)\n",
    "\n",
    "\n",
    "\n",
    "        for rule, is_regex in self.start_rules:\n",
    "            if is_regex:\n",
    "                match = re.search(rule, text)\n",
    "                if match is not None:\n",
    "                    start_index = match.end()  # We want the index after the start rule\n",
    "                    break  # If we've found a match, we can break\n",
    "            else:\n",
    "                idx = text.find(rule)\n",
    "                if idx != -1:\n",
    "                    start_index = idx + len(rule)  # We want the index after the start rule\n",
    "                    break  # If we've found a match, we can break\n",
    "\n",
    "        for rule, is_regex in self.end_rules:\n",
    "            if is_regex:\n",
    "                match = re.search(rule, text[start_index if start_index is not None else 0:])\n",
    "                if match is not None:\n",
    "                    end_index = (start_index if start_index is not None else 0) + match.start()  # We want the index before the end rule\n",
    "                    break  # If we've found a match, we can break\n",
    "            else:\n",
    "                idx = text.find(rule, start_index if start_index is not None else 0)  # We search after the start index\n",
    "                if idx != -1:\n",
    "                    end_index = idx\n",
    "                    break  # If we've found a match, we can break\n",
    "\n",
    "        if start_index is None or end_index is None:\n",
    "            return ''\n",
    "        \n",
    "        return text[start_index:end_index]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890bdade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a243a3f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7395ce01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please login and press Enter to continue...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--disable-extensions\")\n",
    "chrome_options.add_argument(\"--disable-gpu\")\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "driver.get('https://www.linkedin.com/')\n",
    "\n",
    "# Load cookies if they exist\n",
    "try:\n",
    "    cookies = pickle.load(open(\"linkedin_cookies.pkl\", \"rb\"))\n",
    "    for cookie in cookies:\n",
    "        driver.add_cookie(cookie)\n",
    "    driver.refresh()\n",
    "except:\n",
    "    print(\"No cookies found. Manual login required.\")\n",
    "\n",
    "# Check if login is needed\n",
    "try: # not working\n",
    "    element_present = EC.presence_of_element_located((By.ID, 'profile-nav-item')) # check for an element that is only present when logged in\n",
    "    WebDriverWait(driver, 10).until(element_present)\n",
    "except:\n",
    "    # If not logged in\n",
    "    input('Please login and press Enter to continue...')\n",
    "    pickle.dump(driver.get_cookies(), open(\"linkedin_cookies.pkl\", \"wb\")) # save cookies after login\n",
    "\n",
    "\n",
    "# driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e52b16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "af627eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"\n",
    "Extract the names: Please look for patterns indicating a person's name. Names are usually proper nouns and are generally the first information provided in each data point.\n",
    "\n",
    "Find the job titles: Please identify each person's job title. This information follows the name and often contains phrases such as 'Data Scientist', 'Neuroscientist', 'Senior Associate Data Scientist', or a variant that includes the role and any additional qualifiers.\n",
    "\n",
    "Identify the job location: This information typically follows the job title and is usually a city or metropolitan area, such as 'Pasadena, CA' or 'Los Angeles Metropolitan Area'.\n",
    "\n",
    "Find the company names: The company names usually follow the job location. In case there is no current company mentioned, or the person is actively seeking a job, make a note of that by using placeholders like 'None (Job Seeking)' or 'None (No Company Mentioned)'.\n",
    "\n",
    "Construct the dictionary: Organize all the extracted information into a dictionary format where the key represents the type of information (e.g., 'Name', 'Job Titles', 'Job Location', 'Company Name') and the value is a list of all the extracted information of that type in the order of appearance.\n",
    "\n",
    "Formatting the instructions: Always make sure to start the code block with a comment '##BEGIN##', fill in the data accordingly, and end it with '##END##'. All columns of data should align with each other.\n",
    "\n",
    "For example:\n",
    "\n",
    "\n",
    "##BEGIN##\n",
    "\n",
    "DF_TEMP = {\n",
    "    \"Name\": [\"Person 1\", \"Person 2\", ...],\n",
    "    \"Job Titles\": [\"Job 1\", \"Job 2\", ...],\n",
    "    \"Job Location\": [\"Location 1\", \"Location 2\", ...],\n",
    "    \"Company Name\": [\"Company 1\", \"Company 2\", ...]\n",
    "}\n",
    "\n",
    "##END##\n",
    "\n",
    "\n",
    "Replace \"Person 1\", \"Job 1\", \"Location 1\", \"Company 1\", etc., with the actual extracted data.\n",
    "\n",
    "Please make sure to follow these instructions to achieve consistent results.\n",
    "\n",
    "\n",
    "here is the text:\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a408b894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8816db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "91a99291",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def string_parcer_search_page(s):\n",
    "#     pattern = r\"(?<=search result pages)(.*?)(?=Page \\d+ of \\d+)\"\n",
    "#     match = re.search(pattern, s, re.DOTALL)\n",
    "#     if match:\n",
    "#         print(\"Match found!\")\n",
    "#         string_to_GPT = match.group().strip()\n",
    "#         return string_to_GPT\n",
    "#     else:\n",
    "#         return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f284f94a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1855e7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url_text = find_linkedin_info(driver, url_in)\n",
    "# text_finder = Extractor()\n",
    "# text_finder.add_start_rule('search result pages', False)\n",
    "# text_finder.add_end_rule('Page \\d+ of \\d+', True)\n",
    "# text_finder.add_end_rule(\"messaging overlay\", False)\n",
    "# out = text_finder.extract(url_text)\n",
    "# print(out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b2c3b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ef7fb4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url_in = 'https://www.linkedin.com/search/results/people/?keywords=data%20scientist&origin=CLUSTER_EXPANSION&sid=fRq'\n",
    "# driver.get(url_in)\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f780d514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If finding by ID fails, try to find the element by aria-label\n",
    "# next_button = WebDriverWait(driver, 10).until(\n",
    "#     EC.presence_of_element_located((By.CSS_SELECTOR, \"button[aria-label='Next']\"))\n",
    "# )\n",
    "# next_button.click()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "595f1289",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:10: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "<>:10: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "/var/folders/_t/ngsg61p93yg8mhy97ltx2n_80000gn/T/ipykernel_25275/991688616.py:10: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(False, f\"Failed to find by aria-label, error: {str(e2)}\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def click_next_button(driver):\n",
    "    \n",
    "    try:\n",
    "        next_button = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"button[aria-label='Next']\"))\n",
    "        )\n",
    "        next_button.click()\n",
    "\n",
    "    except Exception as e2:\n",
    "        assert(False, f\"Failed to find by aria-label, error: {str(e2)}\")\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "eb9766af",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_in = 'https://www.linkedin.com/search/results/people/?keywords=data%20scientist&origin=CLUSTER_EXPANSION&sid=fRq'\n",
    "driver.get(url_in)\n",
    "\n",
    "time.sleep(10)\n",
    "click_next_button(driver)\n",
    "time.sleep(10)\n",
    "click_next_button(driver)\n",
    "time.sleep(10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fe532737",
   "metadata": {},
   "outputs": [],
   "source": [
    "click_next_button(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c6ac02f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_text = find_linkedin_info(driver)\n",
    "text_finder = Extractor()\n",
    "text_finder.add_start_rule('search result pages', False)\n",
    "text_finder.add_end_rule('Page \\d+ of \\d+', True)\n",
    "text_finder.add_end_rule(\"these results helpful\", False)\n",
    "text_finder.add_end_rule(\"messaging overlay\", False)\n",
    "\n",
    "gpt_text = text_finder.extract(url_text)\n",
    "GPT_INPUT = instructions+gpt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43960465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c4e8ab60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(GPT_INPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e729b0e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2250e637",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4acfc9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "messages = [ {\"role\": \"system\", \"content\": \"You are a intelligent assistant.\"} ]\n",
    "messages.append({\"role\": \"user\", \"content\": GPT_INPUT})\n",
    "chat = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=messages)\n",
    "reply = chat.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bc2f9233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##BEGIN##\n",
      "\n",
      "DF_TEMP = {\n",
      "    \"Name\": [\"Abhinav R.\", \"Shijie (Selene) Xiang\", \"Jinze Xin\", \"Syamil Mohd Razak, PhD\", \"Justin Chen\", \"Malavika Ajith Nair\", \"Marshall R.\", \"Kevin Goldberg\", \"hayden thornton\", \"Lu L.\"],\n",
      "    \"Job Titles\": [\"Incoming Data Scientist at Chevron\", \"Data Scientist at eBay\", \"Data Scientist at Twitter\", \"Data Scientist | Petroleum Engineer\", \"Data Scientist at Snap Inc.\", \"Data Scientist\", \"Data Scientist | web3/DeFi\", \"Data Scientist at Meta\", \"Data Scientist at McKinsey & Company\", \"Data Scientist at Facebook\"],\n",
      "    \"Job Location\": [\"Los Angeles, CA\", \"Los Angeles, CA\", \"Los Angeles Metropolitan Area\", \"Los Angeles Metropolitan Area\", \"Los Angeles Metropolitan Area\", \"United States\", \"United States\", \"Los Angeles, CA\", \"Los Angeles, CA\", \"Los Angeles, CA\"],\n",
      "    \"Company Name\": [\"Chevron\", \"eBay\", \"Twitter\", \"Phillips 66\", \"Snap Inc.\", \"Meta\", \"Stealth Startup\", \"Meta\", \"McKinsey & Company\", \"Facebook\"]\n",
      "}\n",
      "\n",
      "##END##\n"
     ]
    }
   ],
   "source": [
    "print(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d931e11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9f3d997e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Extracted information from the text\n",
    "##BEGIN##\n",
    "\n",
    "DF_TEMP = {\n",
    "    \"Name\": [\"Abhinav R.\", \"Jinze Xin\", \"Syamil Mohd Razak, PhD\", \"Shijie (Selene) Xiang\", \"Malavika Ajith Nair\", \"Marshall R.\", \"Mehrnaz Motamed\", \"Farimah Shirmohammadi, PhD\", \"Kevin Goldberg\", \"Lu L.\"],\n",
    "    \"Job Titles\": [\"Incoming Data Scientist at Chevron | USC Alum\", \"Data Scientist at Twitter\", \"Data Scientist | Petroleum Engineer\", \"Data Scientist at eBay\", \"Data Scientist\", \"Data Scientist | web3/DeFi\", \"Data Scientist - Machine Learning | Deep Learning | Statistics | R | SQL | Python\", \"Data Scientist\", \"Data Scientist at Meta\", \"Data Scientist at Facebook\"],\n",
    "    \"Job Location\": [\"Los Angeles, CA\", \"Los Angeles Metropolitan Area\", \"Los Angeles Metropolitan Area\", \"Los Angeles, CA\", \"United States\", \"United States\", \"Pasadena, CA\", \"Los Angeles, CA\", \"Los Angeles, CA\", \"Los Angeles, CA\"],\n",
    "    \"Company Name\": [\"Chevron\", \"Twitter\", \"Phillips 66\", \"eBay\", \"Meta\", \"Stealth Startup\", \"Endura Technologies\", \"Edison International\", \"Meta\", \"Facebook\"]\n",
    "}\n",
    "\n",
    "\n",
    "# Create a DataFrame\n",
    "DF_TEMP = pd.DataFrame(DF_TEMP)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62bf165",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885936ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "67a72457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Job Titles</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abhinav R.</td>\n",
       "      <td>Incoming Data Scientist at Chevron | USC Alum</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>Chevron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jinze Xin</td>\n",
       "      <td>Data Scientist at Twitter</td>\n",
       "      <td>Los Angeles Metropolitan Area</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Syamil Mohd Razak, PhD</td>\n",
       "      <td>Data Scientist | Petroleum Engineer</td>\n",
       "      <td>Los Angeles Metropolitan Area</td>\n",
       "      <td>Phillips 66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shijie (Selene) Xiang</td>\n",
       "      <td>Data Scientist at eBay</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>eBay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Malavika Ajith Nair</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>United States</td>\n",
       "      <td>Meta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Marshall R.</td>\n",
       "      <td>Data Scientist | web3/DeFi</td>\n",
       "      <td>United States</td>\n",
       "      <td>Stealth Startup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mehrnaz Motamed</td>\n",
       "      <td>Data Scientist - Machine Learning | Deep Learn...</td>\n",
       "      <td>Pasadena, CA</td>\n",
       "      <td>Endura Technologies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Farimah Shirmohammadi, PhD</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>Edison International</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Kevin Goldberg</td>\n",
       "      <td>Data Scientist at Meta</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>Meta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lu L.</td>\n",
       "      <td>Data Scientist at Facebook</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>Facebook</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Name  \\\n",
       "0                  Abhinav R.   \n",
       "1                   Jinze Xin   \n",
       "2      Syamil Mohd Razak, PhD   \n",
       "3       Shijie (Selene) Xiang   \n",
       "4         Malavika Ajith Nair   \n",
       "5                 Marshall R.   \n",
       "6             Mehrnaz Motamed   \n",
       "7  Farimah Shirmohammadi, PhD   \n",
       "8              Kevin Goldberg   \n",
       "9                       Lu L.   \n",
       "\n",
       "                                          Job Titles  \\\n",
       "0      Incoming Data Scientist at Chevron | USC Alum   \n",
       "1                          Data Scientist at Twitter   \n",
       "2                Data Scientist | Petroleum Engineer   \n",
       "3                             Data Scientist at eBay   \n",
       "4                                     Data Scientist   \n",
       "5                         Data Scientist | web3/DeFi   \n",
       "6  Data Scientist - Machine Learning | Deep Learn...   \n",
       "7                                     Data Scientist   \n",
       "8                             Data Scientist at Meta   \n",
       "9                         Data Scientist at Facebook   \n",
       "\n",
       "                    Job Location          Company Name  \n",
       "0                Los Angeles, CA               Chevron  \n",
       "1  Los Angeles Metropolitan Area               Twitter  \n",
       "2  Los Angeles Metropolitan Area           Phillips 66  \n",
       "3                Los Angeles, CA                  eBay  \n",
       "4                  United States                  Meta  \n",
       "5                  United States       Stealth Startup  \n",
       "6                   Pasadena, CA   Endura Technologies  \n",
       "7                Los Angeles, CA  Edison International  \n",
       "8                Los Angeles, CA                  Meta  \n",
       "9                Los Angeles, CA              Facebook  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_TEMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cf477c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8adc2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scrapifurs",
   "language": "python",
   "name": "scrapifurs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
